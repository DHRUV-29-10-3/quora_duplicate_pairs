{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3fecb569-ccba-41e8-b6c6-870d0aa3c5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "from bs4 import BeautifulSoup\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "de7addec-9363-4558-af1f-e695a5b8aaa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"questions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49178ef4-d7e5-46e3-8f5f-07894e1c43fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24dba1b5-b33f-46ef-841e-3b9e09c8cd81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44c8e559-1516-4f6c-813f-d65b9639f51d",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1d2a3db8-df66-4409-bd21-557adc9b8155",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id              0\n",
       "qid1            0\n",
       "qid2            0\n",
       "question1       0\n",
       "question2       0\n",
       "is_duplicate    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f89457c9-8e24-497f-9c6b-f7f859a7c256",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id              0\n",
       "qid1            0\n",
       "qid2            0\n",
       "question1       0\n",
       "question2       0\n",
       "is_duplicate    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6b4fc98f-147f-4690-9791-74517af2f326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is_duplicate\n",
      "0    63.074876\n",
      "1    36.925124\n",
      "Name: count, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='is_duplicate'>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(new_df['is_duplicate'].value_counts()*100/new_df.shape[0])\n",
    "new_df['is_duplicate'].value_counts().plot(kind = 'bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "2e03bba9-29b9-4084-b14d-6663ed228468",
   "metadata": {},
   "outputs": [],
   "source": [
    "# removing punctuations and converting to lower_text() and html tags\n",
    "new_df['question1'] = new_df['question1'].str.lower()\n",
    "new_df['question2'] = new_df['question2'].str.lower()\n",
    "\n",
    "import string \n",
    "exclude = string.punctuation\n",
    "\n",
    "def rem_punct(text):\n",
    "    return text.translate(str.maketrans('','',exclude))\n",
    "\n",
    "new_df['question1']=new_df['question1'].apply(rem_punct)\n",
    "new_df['question2']=new_df['question2'].apply(rem_punct)\n",
    "\n",
    "def remove_html_tags(text):\n",
    "    pattern = re.compile('<.*?>')\n",
    "    return pattern.sub(r'', text)\n",
    "\n",
    "new_df['question1']=new_df['question1'].apply(remove_html_tags)\n",
    "new_df['question2']=new_df['question2'].apply(remove_html_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "668c7efa-5baf-4bb8-a59e-0d79dd004ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def preprocess(q):\n",
    "    \n",
    "    q = str(q).lower().strip()\n",
    "    \n",
    "    # Replace certain special characters with their string equivalents\n",
    "    q = q.replace('%', ' percent')\n",
    "    q = q.replace('$', ' dollar ')\n",
    "    q = q.replace('₹', ' rupee ')\n",
    "    q = q.replace('€', ' euro ')\n",
    "    q = q.replace('@', ' at ')\n",
    "    \n",
    "    # The pattern '[math]' appears around 900 times in the whole dataset.\n",
    "    q = q.replace('[math]', '')\n",
    "    \n",
    "    # Replacing some numbers with string equivalents (not perfect, can be done better to account for more cases)\n",
    "    q = q.replace(',000,000,000 ', 'b ')\n",
    "    q = q.replace(',000,000 ', 'm ')\n",
    "    q = q.replace(',000 ', 'k ')\n",
    "    q = re.sub(r'([0-9]+)000000000', r'\\1b', q)\n",
    "    q = re.sub(r'([0-9]+)000000', r'\\1m', q)\n",
    "    q = re.sub(r'([0-9]+)000', r'\\1k', q)\n",
    "    \n",
    "    # Decontracting words\n",
    "    # https://en.wikipedia.org/wiki/Wikipedia%3aList_of_English_contractions\n",
    "    # https://stackoverflow.com/a/19794953\n",
    "    contractions = { \n",
    "    \"ain't\": \"am not\",\n",
    "    \"aren't\": \"are not\",\n",
    "    \"can't\": \"can not\",\n",
    "    \"can't've\": \"can not have\",\n",
    "    \"'cause\": \"because\",\n",
    "    \"could've\": \"could have\",\n",
    "    \"couldn't\": \"could not\",\n",
    "    \"couldn't've\": \"could not have\",\n",
    "    \"didn't\": \"did not\",\n",
    "    \"doesn't\": \"does not\",\n",
    "    \"don't\": \"do not\",\n",
    "    \"hadn't\": \"had not\",\n",
    "    \"hadn't've\": \"had not have\",\n",
    "    \"hasn't\": \"has not\",\n",
    "    \"haven't\": \"have not\",\n",
    "    \"he'd\": \"he would\",\n",
    "    \"he'd've\": \"he would have\",\n",
    "    \"he'll\": \"he will\",\n",
    "    \"he'll've\": \"he will have\",\n",
    "    \"he's\": \"he is\",\n",
    "    \"how'd\": \"how did\",\n",
    "    \"how'd'y\": \"how do you\",\n",
    "    \"how'll\": \"how will\",\n",
    "    \"how's\": \"how is\",\n",
    "    \"i'd\": \"i would\",\n",
    "    \"i'd've\": \"i would have\",\n",
    "    \"i'll\": \"i will\",\n",
    "    \"i'll've\": \"i will have\",\n",
    "    \"i'm\": \"i am\",\n",
    "    \"i've\": \"i have\",\n",
    "    \"isn't\": \"is not\",\n",
    "    \"it'd\": \"it would\",\n",
    "    \"it'd've\": \"it would have\",\n",
    "    \"it'll\": \"it will\",\n",
    "    \"it'll've\": \"it will have\",\n",
    "    \"it's\": \"it is\",\n",
    "    \"let's\": \"let us\",\n",
    "    \"ma'am\": \"madam\",\n",
    "    \"mayn't\": \"may not\",\n",
    "    \"might've\": \"might have\",\n",
    "    \"mightn't\": \"might not\",\n",
    "    \"mightn't've\": \"might not have\",\n",
    "    \"must've\": \"must have\",\n",
    "    \"mustn't\": \"must not\",\n",
    "    \"mustn't've\": \"must not have\",\n",
    "    \"needn't\": \"need not\",\n",
    "    \"needn't've\": \"need not have\",\n",
    "    \"o'clock\": \"of the clock\",\n",
    "    \"oughtn't\": \"ought not\",\n",
    "    \"oughtn't've\": \"ought not have\",\n",
    "    \"shan't\": \"shall not\",\n",
    "    \"sha'n't\": \"shall not\",\n",
    "    \"shan't've\": \"shall not have\",\n",
    "    \"she'd\": \"she would\",\n",
    "    \"she'd've\": \"she would have\",\n",
    "    \"she'll\": \"she will\",\n",
    "    \"she'll've\": \"she will have\",\n",
    "    \"she's\": \"she is\",\n",
    "    \"should've\": \"should have\",\n",
    "    \"shouldn't\": \"should not\",\n",
    "    \"shouldn't've\": \"should not have\",\n",
    "    \"so've\": \"so have\",\n",
    "    \"so's\": \"so as\",\n",
    "    \"that'd\": \"that would\",\n",
    "    \"that'd've\": \"that would have\",\n",
    "    \"that's\": \"that is\",\n",
    "    \"there'd\": \"there would\",\n",
    "    \"there'd've\": \"there would have\",\n",
    "    \"there's\": \"there is\",\n",
    "    \"they'd\": \"they would\",\n",
    "    \"they'd've\": \"they would have\",\n",
    "    \"they'll\": \"they will\",\n",
    "    \"they'll've\": \"they will have\",\n",
    "    \"they're\": \"they are\",\n",
    "    \"they've\": \"they have\",\n",
    "    \"to've\": \"to have\",\n",
    "    \"wasn't\": \"was not\",\n",
    "    \"we'd\": \"we would\",\n",
    "    \"we'd've\": \"we would have\",\n",
    "    \"we'll\": \"we will\",\n",
    "    \"we'll've\": \"we will have\",\n",
    "    \"we're\": \"we are\",\n",
    "    \"we've\": \"we have\",\n",
    "    \"weren't\": \"were not\",\n",
    "    \"what'll\": \"what will\",\n",
    "    \"what'll've\": \"what will have\",\n",
    "    \"what're\": \"what are\",\n",
    "    \"what's\": \"what is\",\n",
    "    \"what've\": \"what have\",\n",
    "    \"when's\": \"when is\",\n",
    "    \"when've\": \"when have\",\n",
    "    \"where'd\": \"where did\",\n",
    "    \"where's\": \"where is\",\n",
    "    \"where've\": \"where have\",\n",
    "    \"who'll\": \"who will\",\n",
    "    \"who'll've\": \"who will have\",\n",
    "    \"who's\": \"who is\",\n",
    "    \"who've\": \"who have\",\n",
    "    \"why's\": \"why is\",\n",
    "    \"why've\": \"why have\",\n",
    "    \"will've\": \"will have\",\n",
    "    \"won't\": \"will not\",\n",
    "    \"won't've\": \"will not have\",\n",
    "    \"would've\": \"would have\",\n",
    "    \"wouldn't\": \"would not\",\n",
    "    \"wouldn't've\": \"would not have\",\n",
    "    \"y'all\": \"you all\",\n",
    "    \"y'all'd\": \"you all would\",\n",
    "    \"y'all'd've\": \"you all would have\",\n",
    "    \"y'all're\": \"you all are\",\n",
    "    \"y'all've\": \"you all have\",\n",
    "    \"you'd\": \"you would\",\n",
    "    \"you'd've\": \"you would have\",\n",
    "    \"you'll\": \"you will\",\n",
    "    \"you'll've\": \"you will have\",\n",
    "    \"you're\": \"you are\",\n",
    "    \"you've\": \"you have\"\n",
    "    }\n",
    "\n",
    "    q_decontracted = []\n",
    "\n",
    "    for word in q.split():\n",
    "        if word in contractions:\n",
    "            word = contractions[word]\n",
    "\n",
    "        q_decontracted.append(word)\n",
    "\n",
    "    q = ' '.join(q_decontracted)\n",
    "    q = q.replace(\"'ve\", \" have\")\n",
    "    q = q.replace(\"n't\", \" not\")\n",
    "    q = q.replace(\"'re\", \" are\")\n",
    "    q = q.replace(\"'ll\", \" will\")\n",
    "    \n",
    "    \n",
    "    return q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "1973eed7-d44e-4150-9374-4f7fc528fb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df['question1'] = new_df['question1'].apply(preprocess)\n",
    "new_df['question2'] = new_df['question2'].apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f708d8af-5bad-40b3-8990-adfd9ad2df5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>what is the step by step guide to invest in sh...</td>\n",
       "      <td>what is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>what is the story of kohinoor kohinoor diamond</td>\n",
       "      <td>what would happen if the indian government sto...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>how can i increase the speed of my internet co...</td>\n",
       "      <td>how can internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>why am i mentally very lonely how can i solve it</td>\n",
       "      <td>find the remainder when math2324math is divide...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>which one dissolve in water quikly sugar salt ...</td>\n",
       "      <td>which fish would survive in salt water</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2  what is the step by step guide to invest in sh...   \n",
       "1   1     3     4     what is the story of kohinoor kohinoor diamond   \n",
       "2   2     5     6  how can i increase the speed of my internet co...   \n",
       "3   3     7     8   why am i mentally very lonely how can i solve it   \n",
       "4   4     9    10  which one dissolve in water quikly sugar salt ...   \n",
       "\n",
       "                                           question2  is_duplicate  \n",
       "0  what is the step by step guide to invest in sh...             0  \n",
       "1  what would happen if the indian government sto...             0  \n",
       "2  how can internet speed be increased by hacking...             0  \n",
       "3  find the remainder when math2324math is divide...             0  \n",
       "4             which fish would survive in salt water             0  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "cc4633ba-9b0a-474d-b652-8e2779ebe2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f2421c9f-5754-4b49-a148-f16885241c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "# from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "# tokenizer1 = Tokenizer()\n",
    "# tokenizer1.fit_on_texts(new_df['question1'] + \" \" + new_df['question2'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "1318ed16-9964-432a-ae80-e62945921f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text1_sequences = tokenizer1.texts_to_sequences(new_df['question1'])\n",
    "# text2_sequences = tokenizer1.texts_to_sequences(new_df['question2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c918a415-d96c-4e8f-b632-fbf5d305eda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X1 = pad_sequences(text1_sequences, padding='post', maxlen=50)\n",
    "# X2 = pad_sequences(text2_sequences, padding='post', maxlen=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "37e7684b-0067-4712-967d-68fafd84265e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y = new_df['is_duplicate'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "80496ec5-1dca-40d9-9a49-ce9ed9761271",
   "metadata": {},
   "outputs": [],
   "source": [
    "# length = len(tokenizer1.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "c0276cc4-a46c-408b-9ae5-3c29b5041927",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "\n",
    "# # Combine the two sequences into one feature vector, such as by concatenating the padded sequences\n",
    "# X_combined = np.concatenate([X1, X2], axis=1)\n",
    "# X_combined.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "56a63a02-e433-4446-896e-bc33a5869233",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.datasets import imdb\n",
    "# from keras import Sequential\n",
    "# from keras.layers import Dense, SimpleRNN, Embedding, Flatten, LSTM\n",
    "# from sklearn.utils import compute_class_weight\n",
    "\n",
    "# class_weights = compute_class_weight('balanced', classes=np.unique(y), y=y)\n",
    "# class_weight_dict = {0: class_weights[0], 1: class_weights[1]}\n",
    "\n",
    "# model = Sequential()\n",
    "# model.add(Embedding(input_dim=length+1, output_dim=X_combined.shape[1]))\n",
    "# model.add(LSTM(32, return_sequences=False))\n",
    "# model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# # Compile the model\n",
    "# model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# # Train the model\n",
    "# history = model.fit(X_combined, y, epochs=5, validation_split=0.5, class_weight=class_weight_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be96dc8d-d74a-4087-a363-c6a30c1968d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "4a1476c0-764a-46bc-a368-4a10da8c1fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_combined.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "0136e4f3-1647-4abe-a343-7ff036b8bc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# k = 501\n",
    "# [new_df['question1'][k],new_df['question2'][k],new_df['is_duplicate'][k]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "14531718-9925-4311-8803-d9fb96c08d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# a = [\"what is your name\"]\n",
    "# b = [\"hey what is your name\"]\n",
    "\t\t\n",
    "# a = tokenizer1.texts_to_sequences(a)\n",
    "# b = tokenizer1.texts_to_sequences(b)\n",
    "# a = np.array(a)\n",
    "# b = np.array(b)\n",
    "# print(a)\n",
    "# print(b)\n",
    "# a = pad_sequences(a, padding='post', maxlen=50)\n",
    "# b = pad_sequences(b, padding='post', maxlen=50)\n",
    "# x_combined = np.concatenate([a,b], axis = 1)\n",
    "# x_combined.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "ec4d3f0f-d6a8-4d2e-a169-d31be451d0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.predict(x_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "3c2c89c3-f0c2-4e32-9ac4-1604b6efc2a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "c074a3f5-90c4-4e34-a3e4-1cee95b65094",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('lstm_model.pkl', 'wb') as file:\n",
    "#     pickle.dump(model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "65e2d081-9520-4d00-b91e-4fb4859def64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding simple features\n",
    "#1)\n",
    "new_df['q1_len'] = new_df['question1'].str.len()\n",
    "new_df['q2_len'] = new_df['question2'].str.len()\n",
    "\n",
    "#2)\n",
    "new_df['q1_wordcount'] = new_df['question1'].str.split().str.len()\n",
    "new_df['q2_wordcount'] = new_df['question2'].str.split().str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "afb3a3f3-3775-4a0d-97f0-2860d1b72ca6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>q1_len</th>\n",
       "      <th>q2_len</th>\n",
       "      <th>q1_wordcount</th>\n",
       "      <th>q2_wordcount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>what is the step by step guide to invest in sh...</td>\n",
       "      <td>what is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "      <td>56</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>what is the story of kohinoor kohinoor diamond</td>\n",
       "      <td>what would happen if the indian government sto...</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>83</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>how can i increase the speed of my internet co...</td>\n",
       "      <td>how can internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>58</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>why am i mentally very lonely how can i solve it</td>\n",
       "      <td>find the remainder when math2324math is divide...</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>55</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>which one dissolve in water quikly sugar salt ...</td>\n",
       "      <td>which fish would survive in salt water</td>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "      <td>38</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2  what is the step by step guide to invest in sh...   \n",
       "1   1     3     4     what is the story of kohinoor kohinoor diamond   \n",
       "2   2     5     6  how can i increase the speed of my internet co...   \n",
       "3   3     7     8   why am i mentally very lonely how can i solve it   \n",
       "4   4     9    10  which one dissolve in water quikly sugar salt ...   \n",
       "\n",
       "                                           question2  is_duplicate  q1_len  \\\n",
       "0  what is the step by step guide to invest in sh...             0      65   \n",
       "1  what would happen if the indian government sto...             0      46   \n",
       "2  how can internet speed be increased by hacking...             0      72   \n",
       "3  find the remainder when math2324math is divide...             0      48   \n",
       "4             which fish would survive in salt water             0      73   \n",
       "\n",
       "   q2_len  q1_wordcount  q2_wordcount  \n",
       "0      56            14            12  \n",
       "1      83             8            13  \n",
       "2      58            14            10  \n",
       "3      55            11             9  \n",
       "4      38            13             7  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "f094ebe4-4807-46ae-9cf5-37951ee6839d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>q1_len</th>\n",
       "      <th>q2_len</th>\n",
       "      <th>q1_wordcount</th>\n",
       "      <th>q2_wordcount</th>\n",
       "      <th>word_common</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>what is the step by step guide to invest in sh...</td>\n",
       "      <td>what is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "      <td>56</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>what is the story of kohinoor kohinoor diamond</td>\n",
       "      <td>what would happen if the indian government sto...</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>83</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>how can i increase the speed of my internet co...</td>\n",
       "      <td>how can internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>58</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>why am i mentally very lonely how can i solve it</td>\n",
       "      <td>find the remainder when math2324math is divide...</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>55</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>which one dissolve in water quikly sugar salt ...</td>\n",
       "      <td>which fish would survive in salt water</td>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "      <td>38</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2  what is the step by step guide to invest in sh...   \n",
       "1   1     3     4     what is the story of kohinoor kohinoor diamond   \n",
       "2   2     5     6  how can i increase the speed of my internet co...   \n",
       "3   3     7     8   why am i mentally very lonely how can i solve it   \n",
       "4   4     9    10  which one dissolve in water quikly sugar salt ...   \n",
       "\n",
       "                                           question2  is_duplicate  q1_len  \\\n",
       "0  what is the step by step guide to invest in sh...             0      65   \n",
       "1  what would happen if the indian government sto...             0      46   \n",
       "2  how can internet speed be increased by hacking...             0      72   \n",
       "3  find the remainder when math2324math is divide...             0      48   \n",
       "4             which fish would survive in salt water             0      73   \n",
       "\n",
       "   q2_len  q1_wordcount  q2_wordcount  word_common  \n",
       "0      56            14            12           11  \n",
       "1      83             8            13            4  \n",
       "2      58            14            10            4  \n",
       "3      55            11             9            0  \n",
       "4      38            13             7            4  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#3)\n",
    "def common_words(row):\n",
    "    w1 = set(map(lambda word: word.lower().strip(), row['question1'].split(\" \")))\n",
    "    w2 = set(map(lambda word: word.lower().strip(), row['question2'].split(\" \")))    \n",
    "    return len(w1 & w2)\n",
    "\n",
    "new_df['word_common'] = new_df.apply(common_words, axis=1)\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "a0313ea2-af48-4066-acab-74dc64f41fe2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>q1_len</th>\n",
       "      <th>q2_len</th>\n",
       "      <th>q1_wordcount</th>\n",
       "      <th>q2_wordcount</th>\n",
       "      <th>word_common</th>\n",
       "      <th>word_total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>what is the step by step guide to invest in sh...</td>\n",
       "      <td>what is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "      <td>56</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>what is the story of kohinoor kohinoor diamond</td>\n",
       "      <td>what would happen if the indian government sto...</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>83</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>how can i increase the speed of my internet co...</td>\n",
       "      <td>how can internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>58</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>why am i mentally very lonely how can i solve it</td>\n",
       "      <td>find the remainder when math2324math is divide...</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>55</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>which one dissolve in water quikly sugar salt ...</td>\n",
       "      <td>which fish would survive in salt water</td>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "      <td>38</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2  what is the step by step guide to invest in sh...   \n",
       "1   1     3     4     what is the story of kohinoor kohinoor diamond   \n",
       "2   2     5     6  how can i increase the speed of my internet co...   \n",
       "3   3     7     8   why am i mentally very lonely how can i solve it   \n",
       "4   4     9    10  which one dissolve in water quikly sugar salt ...   \n",
       "\n",
       "                                           question2  is_duplicate  q1_len  \\\n",
       "0  what is the step by step guide to invest in sh...             0      65   \n",
       "1  what would happen if the indian government sto...             0      46   \n",
       "2  how can internet speed be increased by hacking...             0      72   \n",
       "3  find the remainder when math2324math is divide...             0      48   \n",
       "4             which fish would survive in salt water             0      73   \n",
       "\n",
       "   q2_len  q1_wordcount  q2_wordcount  word_common  word_total  \n",
       "0      56            14            12           11          23  \n",
       "1      83             8            13            4          18  \n",
       "2      58            14            10            4          24  \n",
       "3      55            11             9            0          19  \n",
       "4      38            13             7            4          20  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#4)\n",
    "def total_words(row):\n",
    "    w1 = set(map(lambda word: word.lower().strip(), row['question1'].split(\" \")))\n",
    "    w2 = set(map(lambda word: word.lower().strip(), row['question2'].split(\" \")))    \n",
    "    return (len(w1) + len(w2))\n",
    "\n",
    "new_df['word_total'] = new_df.apply(total_words, axis=1)\n",
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "3b5632f2-90cf-48b6-a45b-839a38f589d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5) word share \n",
    "\n",
    "new_df['word_share'] = round(new_df['word_common']/new_df['word_total'],2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "0ca01972-58c4-4152-83ff-ab114589733a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>q1_len</th>\n",
       "      <th>q2_len</th>\n",
       "      <th>q1_wordcount</th>\n",
       "      <th>q2_wordcount</th>\n",
       "      <th>word_common</th>\n",
       "      <th>word_total</th>\n",
       "      <th>word_share</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>what is the step by step guide to invest in sh...</td>\n",
       "      <td>what is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "      <td>56</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>11</td>\n",
       "      <td>23</td>\n",
       "      <td>0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>what is the story of kohinoor kohinoor diamond</td>\n",
       "      <td>what would happen if the indian government sto...</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>83</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>0.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>how can i increase the speed of my internet co...</td>\n",
       "      <td>how can internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>58</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>0.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>why am i mentally very lonely how can i solve it</td>\n",
       "      <td>find the remainder when math2324math is divide...</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>55</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>which one dissolve in water quikly sugar salt ...</td>\n",
       "      <td>which fish would survive in salt water</td>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "      <td>38</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>20</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2  what is the step by step guide to invest in sh...   \n",
       "1   1     3     4     what is the story of kohinoor kohinoor diamond   \n",
       "2   2     5     6  how can i increase the speed of my internet co...   \n",
       "3   3     7     8   why am i mentally very lonely how can i solve it   \n",
       "4   4     9    10  which one dissolve in water quikly sugar salt ...   \n",
       "\n",
       "                                           question2  is_duplicate  q1_len  \\\n",
       "0  what is the step by step guide to invest in sh...             0      65   \n",
       "1  what would happen if the indian government sto...             0      46   \n",
       "2  how can internet speed be increased by hacking...             0      72   \n",
       "3  find the remainder when math2324math is divide...             0      48   \n",
       "4             which fish would survive in salt water             0      73   \n",
       "\n",
       "   q2_len  q1_wordcount  q2_wordcount  word_common  word_total  word_share  \n",
       "0      56            14            12           11          23        0.48  \n",
       "1      83             8            13            4          18        0.22  \n",
       "2      58            14            10            4          24        0.17  \n",
       "3      55            11             9            0          19        0.00  \n",
       "4      38            13             7            4          20        0.20  "
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "e2708c76-cd03-4a56-bb15-6e593fd7c777",
   "metadata": {},
   "outputs": [],
   "source": [
    "#) token features \n",
    "#1) cwc_min = common words / min(q1,q2)\n",
    "#2) cwc_max = common words / max(q1,q2)\n",
    "#3) csc_min = common stop words/ min(q1,q2)\n",
    "#4) csc_max = common stop words/ max(q1,q2)\n",
    "#5) ctc_max = common tokens/max(q1,q2)\n",
    "#6) ctc_min = common tokens/min(q1,q2)\n",
    "#7) last_word_equal = check whether last word is equal or not\n",
    "#8) first_word_equal = check whether first word is equal or not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "92222b69-837b-4fbf-9326-9da547d59655",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk, spacy\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "bebce88c-8bd1-44a2-a029-8bbd525e2606",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    return word_tokenize(text)\n",
    "\n",
    "new_df['q1_tokenization'] = new_df['question1'].apply(tokenize)\n",
    "new_df['q2_tokenization'] = new_df['question2'].apply(tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "3b4a1381-14db-4ddb-8a48-29e876495dd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>q1_tokenization</th>\n",
       "      <th>q2_tokenization</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[what, is, the, step, by, step, guide, to, inv...</td>\n",
       "      <td>[what, is, the, step, by, step, guide, to, inv...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     q1_tokenization  \\\n",
       "0  [what, is, the, step, by, step, guide, to, inv...   \n",
       "\n",
       "                                     q2_tokenization  \n",
       "0  [what, is, the, step, by, step, guide, to, inv...  "
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df[['q1_tokenization','q2_tokenization']].head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "3a5f7647-891e-4546-bf6b-27b6b70e30c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "def token_features(row):\n",
    "    q1_tokens = row['q1_tokenization']\n",
    "    q2_tokens = row['q2_tokenization']\n",
    "\n",
    "    stop_words = stopwords.words('english')\n",
    "\n",
    "    safe_div = 0.0001\n",
    "\n",
    "    token_features = [0]*8\n",
    "\n",
    "    if len(q1_tokens) == 0 or len(q2_tokens) == 0:\n",
    "        return token_features\n",
    "\n",
    "    q1_words = set([word for word in q1_tokens if word not in stop_words])\n",
    "    q2_words = set([word for word in q2_tokens if word not in stop_words])\n",
    "\n",
    "    q1_stopwords = set([word for word in q1_tokens if word in stop_words])\n",
    "    q2_stopwords = set([word for word in q2_tokens if word in stop_words])\n",
    "\n",
    "    common_word_count = len(q1_words.intersection(q2_words))\n",
    "\n",
    "    common_stopwords = len(q1_stopwords.intersection(q2_stopwords))\n",
    "\n",
    "    common_tokens = len(set(q1_tokens).intersection(set(q2_tokens)))\n",
    "\n",
    "    first_word_equal = int(q1_tokens[0] == q2_tokens[0])\n",
    "\n",
    "    last_word_equal = int(q1_tokens[-1] == q2_tokens[-1]) \n",
    "\n",
    "    token_features[0] = common_word_count/(len(min(q1_words,q2_words))+safe_div)\n",
    "    token_features[1] = common_word_count/(len(max(q1_words,q2_words))+safe_div)\n",
    "    token_features[2] = common_stopwords/(len(min(q1_stopwords,q2_stopwords))+safe_div)\n",
    "    token_features[3] = common_stopwords/(len(max(q1_stopwords,q2_stopwords))+safe_div)\n",
    "    token_features[4] = common_tokens/(len(min(q1_tokens,q2_tokens))+safe_div)\n",
    "    token_features[5] = common_tokens/(len(max(q1_tokens,q2_tokens))+safe_div)\n",
    "    token_features[6] = first_word_equal\n",
    "    token_features[7] = last_word_equal\n",
    "\n",
    "    return token_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "ddfc75cc-c26d-4c08-bc7b-cb48ed3fd1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_features = new_df.apply(token_features, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "f32dbf46-03b1-402e-9d90-09fbba735ecf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [0.999980000399992, 0.8333194446759221, 0.9999...\n",
       "1    [0.6666444451851604, 0.6666444451851604, 0.499...\n",
       "2    [0.3333277778703688, 0.3333277778703688, 0.249...\n",
       "3                 [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0, 0]\n",
       "4    [0.19999800001999982, 0.19999800001999982, 0.9...\n",
       "dtype: object"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "08924f02-c783-4e19-9ac7-978988190cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df['cwc_min'] = list(map(lambda x : x[0], token_features))\n",
    "new_df['cwc_max'] = list(map(lambda x : x[1], token_features))\n",
    "new_df['csc_min'] = list(map(lambda x : x[2], token_features))\n",
    "new_df['csc_max'] = list(map(lambda x : x[3], token_features))\n",
    "new_df['ctw_min'] = list(map(lambda x : x[4], token_features))\n",
    "new_df['ctw_max'] = list(map(lambda x : x[5], token_features))\n",
    "new_df['first_word_match'] = list(map(lambda x : x[6], token_features))\n",
    "new_df['last_word_match'] = list(map(lambda x : x[7], token_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "e0cebc87-e1f3-49a5-9566-91a364e31221",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>q1_len</th>\n",
       "      <th>q2_len</th>\n",
       "      <th>q1_wordcount</th>\n",
       "      <th>q2_wordcount</th>\n",
       "      <th>...</th>\n",
       "      <th>q1_tokenization</th>\n",
       "      <th>q2_tokenization</th>\n",
       "      <th>cwc_min</th>\n",
       "      <th>cwc_max</th>\n",
       "      <th>csc_min</th>\n",
       "      <th>csc_max</th>\n",
       "      <th>ctw_min</th>\n",
       "      <th>ctw_max</th>\n",
       "      <th>first_word_match</th>\n",
       "      <th>last_word_match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>what is the step by step guide to invest in sh...</td>\n",
       "      <td>what is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "      <td>56</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>[what, is, the, step, by, step, guide, to, inv...</td>\n",
       "      <td>[what, is, the, step, by, step, guide, to, inv...</td>\n",
       "      <td>0.999980</td>\n",
       "      <td>0.833319</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>0.916659</td>\n",
       "      <td>0.785709</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>what is the story of kohinoor kohinoor diamond</td>\n",
       "      <td>what would happen if the indian government sto...</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>83</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>[what, is, the, story, of, kohinoor, kohinoor,...</td>\n",
       "      <td>[what, would, happen, if, the, indian, governm...</td>\n",
       "      <td>0.666644</td>\n",
       "      <td>0.666644</td>\n",
       "      <td>0.499988</td>\n",
       "      <td>0.499988</td>\n",
       "      <td>0.499994</td>\n",
       "      <td>0.307690</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>how can i increase the speed of my internet co...</td>\n",
       "      <td>how can internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>58</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>[how, can, i, increase, the, speed, of, my, in...</td>\n",
       "      <td>[how, can, internet, speed, be, increased, by,...</td>\n",
       "      <td>0.333328</td>\n",
       "      <td>0.333328</td>\n",
       "      <td>0.249997</td>\n",
       "      <td>0.249997</td>\n",
       "      <td>0.285712</td>\n",
       "      <td>0.399996</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>why am i mentally very lonely how can i solve it</td>\n",
       "      <td>find the remainder when math2324math is divide...</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>55</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>[why, am, i, mentally, very, lonely, how, can,...</td>\n",
       "      <td>[find, the, remainder, when, math2324math, is,...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>which one dissolve in water quikly sugar salt ...</td>\n",
       "      <td>which fish would survive in salt water</td>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "      <td>38</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>[which, one, dissolve, in, water, quikly, suga...</td>\n",
       "      <td>[which, fish, would, survive, in, salt, water]</td>\n",
       "      <td>0.199998</td>\n",
       "      <td>0.199998</td>\n",
       "      <td>0.999950</td>\n",
       "      <td>0.666644</td>\n",
       "      <td>0.571420</td>\n",
       "      <td>0.307690</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2  what is the step by step guide to invest in sh...   \n",
       "1   1     3     4     what is the story of kohinoor kohinoor diamond   \n",
       "2   2     5     6  how can i increase the speed of my internet co...   \n",
       "3   3     7     8   why am i mentally very lonely how can i solve it   \n",
       "4   4     9    10  which one dissolve in water quikly sugar salt ...   \n",
       "\n",
       "                                           question2  is_duplicate  q1_len  \\\n",
       "0  what is the step by step guide to invest in sh...             0      65   \n",
       "1  what would happen if the indian government sto...             0      46   \n",
       "2  how can internet speed be increased by hacking...             0      72   \n",
       "3  find the remainder when math2324math is divide...             0      48   \n",
       "4             which fish would survive in salt water             0      73   \n",
       "\n",
       "   q2_len  q1_wordcount  q2_wordcount  ...  \\\n",
       "0      56            14            12  ...   \n",
       "1      83             8            13  ...   \n",
       "2      58            14            10  ...   \n",
       "3      55            11             9  ...   \n",
       "4      38            13             7  ...   \n",
       "\n",
       "                                     q1_tokenization  \\\n",
       "0  [what, is, the, step, by, step, guide, to, inv...   \n",
       "1  [what, is, the, story, of, kohinoor, kohinoor,...   \n",
       "2  [how, can, i, increase, the, speed, of, my, in...   \n",
       "3  [why, am, i, mentally, very, lonely, how, can,...   \n",
       "4  [which, one, dissolve, in, water, quikly, suga...   \n",
       "\n",
       "                                     q2_tokenization   cwc_min   cwc_max  \\\n",
       "0  [what, is, the, step, by, step, guide, to, inv...  0.999980  0.833319   \n",
       "1  [what, would, happen, if, the, indian, governm...  0.666644  0.666644   \n",
       "2  [how, can, internet, speed, be, increased, by,...  0.333328  0.333328   \n",
       "3  [find, the, remainder, when, math2324math, is,...  0.000000  0.000000   \n",
       "4     [which, fish, would, survive, in, salt, water]  0.199998  0.199998   \n",
       "\n",
       "    csc_min   csc_max   ctw_min   ctw_max  first_word_match  last_word_match  \n",
       "0  0.999983  0.999983  0.916659  0.785709                 1                0  \n",
       "1  0.499988  0.499988  0.499994  0.307690                 1                0  \n",
       "2  0.249997  0.249997  0.285712  0.399996                 1                0  \n",
       "3  0.000000  0.000000  0.000000  0.000000                 0                0  \n",
       "4  0.999950  0.666644  0.571420  0.307690                 1                0  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "c4ff4c5d-1ef9-4aa8-b856-3cecb9ce6ba8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>q1_len</th>\n",
       "      <th>q2_len</th>\n",
       "      <th>q1_wordcount</th>\n",
       "      <th>q2_wordcount</th>\n",
       "      <th>...</th>\n",
       "      <th>q1_tokenization</th>\n",
       "      <th>q2_tokenization</th>\n",
       "      <th>cwc_min</th>\n",
       "      <th>cwc_max</th>\n",
       "      <th>csc_min</th>\n",
       "      <th>csc_max</th>\n",
       "      <th>ctw_min</th>\n",
       "      <th>ctw_max</th>\n",
       "      <th>first_word_match</th>\n",
       "      <th>last_word_match</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>what is the step by step guide to invest in sh...</td>\n",
       "      <td>what is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "      <td>56</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>[what, is, the, step, by, step, guide, to, inv...</td>\n",
       "      <td>[what, is, the, step, by, step, guide, to, inv...</td>\n",
       "      <td>0.999980</td>\n",
       "      <td>0.833319</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>0.916659</td>\n",
       "      <td>0.785709</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>what is the story of kohinoor kohinoor diamond</td>\n",
       "      <td>what would happen if the indian government sto...</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>83</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>[what, is, the, story, of, kohinoor, kohinoor,...</td>\n",
       "      <td>[what, would, happen, if, the, indian, governm...</td>\n",
       "      <td>0.666644</td>\n",
       "      <td>0.666644</td>\n",
       "      <td>0.499988</td>\n",
       "      <td>0.499988</td>\n",
       "      <td>0.499994</td>\n",
       "      <td>0.307690</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>how can i increase the speed of my internet co...</td>\n",
       "      <td>how can internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>58</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>[how, can, i, increase, the, speed, of, my, in...</td>\n",
       "      <td>[how, can, internet, speed, be, increased, by,...</td>\n",
       "      <td>0.333328</td>\n",
       "      <td>0.333328</td>\n",
       "      <td>0.249997</td>\n",
       "      <td>0.249997</td>\n",
       "      <td>0.285712</td>\n",
       "      <td>0.399996</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>why am i mentally very lonely how can i solve it</td>\n",
       "      <td>find the remainder when math2324math is divide...</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>55</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>[why, am, i, mentally, very, lonely, how, can,...</td>\n",
       "      <td>[find, the, remainder, when, math2324math, is,...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>which one dissolve in water quikly sugar salt ...</td>\n",
       "      <td>which fish would survive in salt water</td>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "      <td>38</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>[which, one, dissolve, in, water, quikly, suga...</td>\n",
       "      <td>[which, fish, would, survive, in, salt, water]</td>\n",
       "      <td>0.199998</td>\n",
       "      <td>0.199998</td>\n",
       "      <td>0.999950</td>\n",
       "      <td>0.666644</td>\n",
       "      <td>0.571420</td>\n",
       "      <td>0.307690</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2  what is the step by step guide to invest in sh...   \n",
       "1   1     3     4     what is the story of kohinoor kohinoor diamond   \n",
       "2   2     5     6  how can i increase the speed of my internet co...   \n",
       "3   3     7     8   why am i mentally very lonely how can i solve it   \n",
       "4   4     9    10  which one dissolve in water quikly sugar salt ...   \n",
       "\n",
       "                                           question2  is_duplicate  q1_len  \\\n",
       "0  what is the step by step guide to invest in sh...             0      65   \n",
       "1  what would happen if the indian government sto...             0      46   \n",
       "2  how can internet speed be increased by hacking...             0      72   \n",
       "3  find the remainder when math2324math is divide...             0      48   \n",
       "4             which fish would survive in salt water             0      73   \n",
       "\n",
       "   q2_len  q1_wordcount  q2_wordcount  ...  \\\n",
       "0      56            14            12  ...   \n",
       "1      83             8            13  ...   \n",
       "2      58            14            10  ...   \n",
       "3      55            11             9  ...   \n",
       "4      38            13             7  ...   \n",
       "\n",
       "                                     q1_tokenization  \\\n",
       "0  [what, is, the, step, by, step, guide, to, inv...   \n",
       "1  [what, is, the, story, of, kohinoor, kohinoor,...   \n",
       "2  [how, can, i, increase, the, speed, of, my, in...   \n",
       "3  [why, am, i, mentally, very, lonely, how, can,...   \n",
       "4  [which, one, dissolve, in, water, quikly, suga...   \n",
       "\n",
       "                                     q2_tokenization   cwc_min   cwc_max  \\\n",
       "0  [what, is, the, step, by, step, guide, to, inv...  0.999980  0.833319   \n",
       "1  [what, would, happen, if, the, indian, governm...  0.666644  0.666644   \n",
       "2  [how, can, internet, speed, be, increased, by,...  0.333328  0.333328   \n",
       "3  [find, the, remainder, when, math2324math, is,...  0.000000  0.000000   \n",
       "4     [which, fish, would, survive, in, salt, water]  0.199998  0.199998   \n",
       "\n",
       "    csc_min   csc_max   ctw_min   ctw_max  first_word_match  last_word_match  \n",
       "0  0.999983  0.999983  0.916659  0.785709                 1                0  \n",
       "1  0.499988  0.499988  0.499994  0.307690                 1                0  \n",
       "2  0.249997  0.249997  0.285712  0.399996                 1                0  \n",
       "3  0.000000  0.000000  0.000000  0.000000                 0                0  \n",
       "4  0.999950  0.666644  0.571420  0.307690                 1                0  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "702646f4-f9a2-4ced-b023-81a71c07443d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import distance\n",
    "\n",
    "def fetch_length_features(row):\n",
    "    \n",
    "    q1 = row['question1']\n",
    "    q2 = row['question2']\n",
    "    \n",
    "    length_features = [0]*3\n",
    "    \n",
    "    # Converting the Sentence into Tokens: \n",
    "    q1_tokens = q1.split()\n",
    "    q2_tokens = q2.split()\n",
    "    \n",
    "    if len(q1_tokens) == 0 or len(q2_tokens) == 0:\n",
    "        return length_features\n",
    "    \n",
    "    # Absolute length features\n",
    "    length_features[0] = abs(len(q1_tokens) - len(q2_tokens))\n",
    "    \n",
    "    #Average Token Length of both Questions\n",
    "    length_features[1] = (len(q1_tokens) + len(q2_tokens))/2\n",
    "    \n",
    "    strs = list(distance.lcsubstrings(q1, q2))\n",
    "    if strs:\n",
    "        length_features[2] = len(strs[0]) / (min(len(q1), len(q2)) + 1)\n",
    "    else:\n",
    "        length_features[2] = 0\n",
    "    \n",
    "    return length_features\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "10983f72-c38a-4627-8cae-0a89ba0891fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           [2, 13.0, 0.9824561403508771]\n",
       "1           [5, 10.5, 0.5531914893617021]\n",
       "2           [4, 12.0, 0.1694915254237288]\n",
       "3          [2, 10.0, 0.04081632653061224]\n",
       "4          [6, 10.0, 0.15384615384615385]\n",
       "                       ...               \n",
       "404346      [1, 13.5, 0.3924050632911392]\n",
       "404347       [1, 8.5, 0.6341463414634146]\n",
       "404348                   [1, 3.5, 0.3125]\n",
       "404349    [8, 21.0, 0.053763440860215055]\n",
       "404350       [2, 9.0, 0.6216216216216216]\n",
       "Length: 404348, dtype: object"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length_features = new_df.apply(fetch_length_features, axis = 1)\n",
    "length_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "253d47cb-de07-4651-b715-b52c6ba75b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df['abs_len_diff'] = list(map(lambda x: x[0], length_features))\n",
    "new_df['mean_len'] = list(map(lambda x: x[1], length_features))\n",
    "new_df['longest_substr_ratio'] = list(map(lambda x: x[2], length_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "4e4d645f-8828-4ffc-ad5d-c957ddb2f24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "def fetch_fuzzy_features(row):\n",
    "    \n",
    "    q1 = row['question1']\n",
    "    q2 = row['question2']\n",
    "    \n",
    "    fuzzy_features = [0.0]*4\n",
    "    \n",
    "    # fuzz_ratio\n",
    "    fuzzy_features[0] = fuzz.QRatio(q1, q2)\n",
    "\n",
    "    # fuzz_partial_ratio\n",
    "    fuzzy_features[1] = fuzz.partial_ratio(q1, q2)\n",
    "\n",
    "    # token_sort_ratio\n",
    "    fuzzy_features[2] = fuzz.token_sort_ratio(q1, q2)\n",
    "\n",
    "    # token_set_ratio\n",
    "    fuzzy_features[3] = fuzz.token_set_ratio(q1, q2)\n",
    "\n",
    "    return fuzzy_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "d4b85bb0-61fa-47c1-a914-755c1404022e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fuzzy_features = new_df.apply(fetch_fuzzy_features, axis = 1)\n",
    "\n",
    "# Creating new feature columns for fuzzy features\n",
    "new_df['fuzz_ratio'] = list(map(lambda x: x[0], fuzzy_features))\n",
    "new_df['fuzz_partial_ratio'] = list(map(lambda x: x[1], fuzzy_features))\n",
    "new_df['token_sort_ratio'] = list(map(lambda x: x[2], fuzzy_features))\n",
    "new_df['token_set_ratio'] = list(map(lambda x: x[3], fuzzy_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "e2e24d9e-d098-412e-a075-04c53f8886a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>qid1</th>\n",
       "      <th>qid2</th>\n",
       "      <th>question1</th>\n",
       "      <th>question2</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>q1_len</th>\n",
       "      <th>q2_len</th>\n",
       "      <th>q1_wordcount</th>\n",
       "      <th>q2_wordcount</th>\n",
       "      <th>...</th>\n",
       "      <th>ctw_max</th>\n",
       "      <th>first_word_match</th>\n",
       "      <th>last_word_match</th>\n",
       "      <th>abs_len_diff</th>\n",
       "      <th>mean_len</th>\n",
       "      <th>longest_substr_ratio</th>\n",
       "      <th>fuzz_ratio</th>\n",
       "      <th>fuzz_partial_ratio</th>\n",
       "      <th>token_sort_ratio</th>\n",
       "      <th>token_set_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>what is the step by step guide to invest in sh...</td>\n",
       "      <td>what is the step by step guide to invest in sh...</td>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "      <td>56</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>0.785709</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.982456</td>\n",
       "      <td>93</td>\n",
       "      <td>100</td>\n",
       "      <td>93</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>what is the story of kohinoor kohinoor diamond</td>\n",
       "      <td>what would happen if the indian government sto...</td>\n",
       "      <td>0</td>\n",
       "      <td>46</td>\n",
       "      <td>83</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>0.307690</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>10.5</td>\n",
       "      <td>0.553191</td>\n",
       "      <td>64</td>\n",
       "      <td>72</td>\n",
       "      <td>62</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>how can i increase the speed of my internet co...</td>\n",
       "      <td>how can internet speed be increased by hacking...</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>58</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>...</td>\n",
       "      <td>0.399996</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.169492</td>\n",
       "      <td>43</td>\n",
       "      <td>46</td>\n",
       "      <td>63</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>why am i mentally very lonely how can i solve it</td>\n",
       "      <td>find the remainder when math2324math is divide...</td>\n",
       "      <td>0</td>\n",
       "      <td>48</td>\n",
       "      <td>55</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.040816</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>25</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>which one dissolve in water quikly sugar salt ...</td>\n",
       "      <td>which fish would survive in salt water</td>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "      <td>38</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.307690</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>36</td>\n",
       "      <td>55</td>\n",
       "      <td>47</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  qid1  qid2                                          question1  \\\n",
       "0   0     1     2  what is the step by step guide to invest in sh...   \n",
       "1   1     3     4     what is the story of kohinoor kohinoor diamond   \n",
       "2   2     5     6  how can i increase the speed of my internet co...   \n",
       "3   3     7     8   why am i mentally very lonely how can i solve it   \n",
       "4   4     9    10  which one dissolve in water quikly sugar salt ...   \n",
       "\n",
       "                                           question2  is_duplicate  q1_len  \\\n",
       "0  what is the step by step guide to invest in sh...             0      65   \n",
       "1  what would happen if the indian government sto...             0      46   \n",
       "2  how can internet speed be increased by hacking...             0      72   \n",
       "3  find the remainder when math2324math is divide...             0      48   \n",
       "4             which fish would survive in salt water             0      73   \n",
       "\n",
       "   q2_len  q1_wordcount  q2_wordcount  ...   ctw_max  first_word_match  \\\n",
       "0      56            14            12  ...  0.785709                 1   \n",
       "1      83             8            13  ...  0.307690                 1   \n",
       "2      58            14            10  ...  0.399996                 1   \n",
       "3      55            11             9  ...  0.000000                 0   \n",
       "4      38            13             7  ...  0.307690                 1   \n",
       "\n",
       "   last_word_match abs_len_diff mean_len  longest_substr_ratio  fuzz_ratio  \\\n",
       "0                0            2     13.0              0.982456          93   \n",
       "1                0            5     10.5              0.553191          64   \n",
       "2                0            4     12.0              0.169492          43   \n",
       "3                0            2     10.0              0.040816           8   \n",
       "4                0            6     10.0              0.153846          36   \n",
       "\n",
       "   fuzz_partial_ratio  token_sort_ratio  token_set_ratio  \n",
       "0                 100                93              100  \n",
       "1                  72                62               81  \n",
       "2                  46                63               63  \n",
       "3                  10                25               26  \n",
       "4                  55                47               67  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "ae214103-9d9e-4378-99e6-e61c3cee2fce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'qid1', 'qid2', 'question1', 'question2', 'is_duplicate',\n",
       "       'q1_len', 'q2_len', 'q1_wordcount', 'q2_wordcount', 'word_common',\n",
       "       'word_total', 'word_share', 'q1_tokenization', 'q2_tokenization',\n",
       "       'cwc_min', 'cwc_max', 'csc_min', 'csc_max', 'ctw_min', 'ctw_max',\n",
       "       'first_word_match', 'last_word_match', 'abs_len_diff', 'mean_len',\n",
       "       'longest_substr_ratio', 'fuzz_ratio', 'fuzz_partial_ratio',\n",
       "       'token_sort_ratio', 'token_set_ratio'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "9697041f-0b55-492a-9ce2-46fa1716688e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.pairplot(new_df[['ctw_min', 'cwc_min', 'csc_min', 'is_duplicate']],hue='is_duplicate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "a14c30c0-915e-4ea1-95dd-15a7d6d566d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.pairplot(new_df[['ctw_max', 'cwc_max', 'csc_max', 'is_duplicate']],hue='is_duplicate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "1fb801af-2661-4daa-bc24-0b520cc32c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.pairplot(new_df[['first_word_match', 'last_word_match', 'is_duplicate']],hue='is_duplicate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "9fc4893c-5d01-489a-9f16-62e45e301f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.pairplot(new_df[['mean_len', 'abs_len_diff','longest_substr_ratio', 'is_duplicate']],hue='is_duplicate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "3d952839-a477-421e-8354-9996a1c4506d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.pairplot(new_df[['q1_wordcount', 'q2_wordcount', 'word_common',\t'word_total', 'word_share', 'is_duplicate']],hue='is_duplicate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "8ef9e9cd-b303-4616-a6f1-380330fb0c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.drop(columns=['q1_tokenization','q2_tokenization'], inplace =True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "b47c5de5-9154-4477-9d81-0c2e30b5ce03",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.to_csv(\"preprocessed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "ef471ac5-ae87-497a-a59d-c70eddbc4a60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'qid1', 'qid2', 'question1', 'question2', 'is_duplicate',\n",
       "       'q1_len', 'q2_len', 'q1_wordcount', 'q2_wordcount', 'word_common',\n",
       "       'word_total', 'word_share', 'cwc_min', 'cwc_max', 'csc_min', 'csc_max',\n",
       "       'ctw_min', 'ctw_max', 'first_word_match', 'last_word_match',\n",
       "       'abs_len_diff', 'mean_len', 'longest_substr_ratio', 'fuzz_ratio',\n",
       "       'fuzz_partial_ratio', 'token_sort_ratio', 'token_set_ratio'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "81a7cf0e-b347-4bfe-9639-03b37988fea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = new_df.iloc[:,6:].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "3f35960c-e015-4ad4-a582-f713448748f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = new_df.iloc[:,5].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "59f84a11-7515-47d2-b4ee-39ee725291ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(323478, 22)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "9a909ef5-075d-4ab5-a4b1-c9e61e0c79a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m5055/5055\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m304s\u001b[0m 60ms/step - accuracy: 0.6674 - loss: 0.5544 - val_accuracy: 0.6857 - val_loss: 0.5346\n",
      "Epoch 2/10\n",
      "\u001b[1m1579/5055\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:17\u001b[0m 57ms/step - accuracy: 0.6812 - loss: 0.5305"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[131], line 18\u001b[0m\n\u001b[0;32m     15\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_weight_dict\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:368\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[0;32m    366\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[0;32m    367\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m--> 368\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    369\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n\u001b[0;32m    370\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:216\u001b[0m, in \u001b[0;36mTensorFlowTrainer._make_function.<locals>.function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m    212\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfunction\u001b[39m(iterator):\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[0;32m    214\u001b[0m         iterator, (tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mIterator, tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mDistributedIterator)\n\u001b[0;32m    215\u001b[0m     ):\n\u001b[1;32m--> 216\u001b[0m         opt_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs\u001b[38;5;241m.\u001b[39mhas_value():\n\u001b[0;32m    218\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[0;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1324\u001b[0m     args,\n\u001b[0;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1326\u001b[0m     executing_eagerly)\n\u001b[0;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\context.py:1683\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1681\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1682\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1683\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1684\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1685\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1686\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1687\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1688\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1689\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1690\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1691\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1692\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1693\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1697\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1698\u001b[0m   )\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras.datasets import imdb\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense, SimpleRNN, Embedding, Flatten, LSTM\n",
    "from sklearn.utils import compute_class_weight\n",
    "\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(y), y=y)\n",
    "class_weight_dict = {0: class_weights[0], 1: class_weights[1]}\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=X_train.shape[0], output_dim=X_train.shape[1]))\n",
    "model.add(LSTM(32, return_sequences=False))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=10, validation_split=0.5, class_weight=class_weight_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79d8248-1a52-42bb-80c8-c0966d490e16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc993a14-baa3-4f66-9c85-dee62fb17316",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472d9a50-f155-4991-a355-0a8513780c26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ddca97-84ec-4931-8d90-16393c048384",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ecaa9ec-ee4d-4338-bcca-11498ad9e9ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89bd2517-ffbc-4ce6-bbe0-5048a8ba3551",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e1089a9-12d8-41eb-ae6b-e3938e85c802",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d517dc-ac1e-49dc-827a-e1919c48a24f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc0329f-e357-4d62-9569-c281a74e90e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c495c0-3a6e-4528-9953-ac539fe284e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa27581-afee-4227-b2db-a9f5c1095f9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c537cbd1-65cf-4538-a855-8f5c34cd692b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a001038d-0ace-448c-a593-a2d634387bf5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
